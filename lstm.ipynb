{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249a8202-4148-4061-8d71-90d59d3c9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (5.29.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (72.1.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhivyan jeshua\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.7.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09eda15-bdaa-4d38-9668-c4804a875b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<frozen runpy>\"\u001b[0m, line \u001b[35m198\u001b[0m, in \u001b[35m_run_module_as_main\u001b[0m\n",
      "  File \u001b[35m\"<frozen runpy>\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35m_run_code\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Dhivyan Jeshua\\anaconda3\\Scripts\\kaggle.exe\\__main__.py\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Dhivyan Jeshua\\anaconda3\\Lib\\site-packages\\kaggle\\cli.py\"\u001b[0m, line \u001b[35m68\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    out = args.func(**command_args)\n",
      "  File \u001b[35m\"C:\\Users\\Dhivyan Jeshua\\anaconda3\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\"\u001b[0m, line \u001b[35m1741\u001b[0m, in \u001b[35mdataset_download_cli\u001b[0m\n",
      "    with \u001b[31mself.build_kaggle_client\u001b[0m\u001b[1;31m()\u001b[0m as kaggle:\n",
      "         \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Dhivyan Jeshua\\anaconda3\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\"\u001b[0m, line \u001b[35m688\u001b[0m, in \u001b[35mbuild_kaggle_client\u001b[0m\n",
      "    username=\u001b[31mself.config_values\u001b[0m\u001b[1;31m['username']\u001b[0m,\n",
      "             \u001b[31m~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mKeyError\u001b[0m: \u001b[35m'username'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'weather-dataset' downloaded and unzipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# This uses the system's command line. The '!' runs it from inside the notebook.\n",
    "!kaggle datasets download -d muthuj7/weather-dataset\n",
    "\n",
    "# Unzip the downloaded file\n",
    "!unzip -q weather-dataset.zip\n",
    "\n",
    "print(\"Dataset 'weather-dataset' downloaded and unzipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79224923-fd4a-42c2-8be9-cc70b828818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (96432, 3)\n",
      "Training data shape: (77145, 3)\n",
      "Test data shape: (19287, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhivyan Jeshua\\AppData\\Local\\Temp\\ipykernel_42748\\1071772387.py:26: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_full = df_full.resample('h').interpolate(method='time')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    df_full = pd.read_csv('weatherHistory.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the weatherHistory.csv file.\")\n",
    "    raise\n",
    "\n",
    "# --- 2. Clean and Set Index ---\n",
    "# Convert date column to datetime objects\n",
    "df_full['Formatted Date'] = pd.to_datetime(df_full['Formatted Date'], utc=True)\n",
    "\n",
    "# Set the date as the index and sort the data\n",
    "df_full = df_full.set_index('Formatted Date').sort_index()\n",
    "\n",
    "# --- Handle duplicate index entries before resampling ---\n",
    "# Keep the first occurrence of each timestamp\n",
    "df_full = df_full[~df_full.index.duplicated(keep='first')]\n",
    "\n",
    "# The data is hourly, but we resample to 'h' to fill any missing time steps\n",
    "# We use 'interpolate' to fill gaps (e.g., missing hours)\n",
    "# Using 'h' as 'H' is deprecated\n",
    "df_full = df_full.resample('h').interpolate(method='time')\n",
    "\n",
    "# --- 3. Select Features (X) and Target (Y) ---\n",
    "N_FEATURES = 3\n",
    "features = ['Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)']\n",
    "target = 'Temperature (C)'\n",
    "\n",
    "# Drop rows where our target or features are missing\n",
    "df_clean = df_full[features + [target]].dropna()\n",
    "\n",
    "X = df_clean[features].values\n",
    "Y = df_clean[target].values.reshape(-1, 1)\n",
    "\n",
    "print(f\"Original data shape: {X.shape}\")\n",
    "\n",
    "# --- 4. Scale Data ---\n",
    "# Standard practice for LSTMs is to scale features to [0, 1]\n",
    "feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = feature_scaler.fit_transform(X)\n",
    "\n",
    "# Scale the target (Temperature) to [0, 1]\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaled = target_scaler.fit_transform(Y)\n",
    "\n",
    "# --- 5. Create Train/Test Split ---\n",
    "# We must split time-series data sequentially\n",
    "test_percent = 0.2\n",
    "split_idx = int(len(Y_scaled) * (1 - test_percent))\n",
    "\n",
    "X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "Y_train, Y_test = Y_scaled[:split_idx], Y_scaled[split_idx:]\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d4d9062-3275-4cc1-b682-1d6abf13c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences shape: (77121, 24, 3)\n",
      "Test sequences shape: (19263, 24, 3)\n",
      "\n",
      "--- Training LSTM Model on SELECTED Features ---\n",
      "Epoch 1/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0096 - val_loss: 0.0189\n",
      "Epoch 2/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - loss: 0.0070 - val_loss: 0.0183\n",
      "Epoch 3/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - loss: 0.0069 - val_loss: 0.0183\n",
      "Epoch 4/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - loss: 0.0064 - val_loss: 0.0187\n",
      "Epoch 5/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - loss: 0.0064 - val_loss: 0.0182\n",
      "Epoch 6/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - loss: 0.0064 - val_loss: 0.0180\n",
      "Epoch 7/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0178\n",
      "Epoch 8/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 14ms/step - loss: 0.0064 - val_loss: 0.0181\n",
      "Epoch 9/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15ms/step - loss: 0.0065 - val_loss: 0.0186\n",
      "Epoch 10/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - loss: 0.0066 - val_loss: 0.0183\n",
      "Epoch 11/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 14ms/step - loss: 0.0064 - val_loss: 0.0185\n",
      "Epoch 12/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0196\n",
      "Epoch 13/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - loss: 0.0066 - val_loss: 0.0194\n",
      "Epoch 14/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15ms/step - loss: 0.0070 - val_loss: 0.0196\n",
      "Epoch 15/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 16ms/step - loss: 0.0069 - val_loss: 0.0178\n",
      "Epoch 16/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 0.0067 - val_loss: 0.0195\n",
      "Epoch 17/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 0.0064 - val_loss: 0.0173\n",
      "Epoch 18/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - loss: 0.0067 - val_loss: 0.0183\n",
      "Epoch 19/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - loss: 0.0070 - val_loss: 0.0168\n",
      "Epoch 20/20\n",
      "\u001b[1m2411/2411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - loss: 0.0068 - val_loss: 0.0182\n",
      "--- Model Training Complete ---\n",
      "\u001b[1m602/602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Test RMSE: 8.3199 (degrees C)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- 1. Create Sequences for LSTM ---\n",
    "def create_sequences(X, y, time_steps=24):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 24 # Use 24 hours of history\n",
    "X_seq_train, Y_seq_train = create_sequences(X_train, Y_train, TIME_STEPS)\n",
    "X_seq_test, Y_seq_test = create_sequences(X_test, Y_test, TIME_STEPS)\n",
    "\n",
    "# The shape will now be [samples, 24, 3]\n",
    "print(f\"Training sequences shape: {X_seq_train.shape}\")\n",
    "print(f\"Test sequences shape: {X_seq_test.shape}\")\n",
    "\n",
    "# --- 2. Build the LSTM Model ---\n",
    "model_lstm_simple = Sequential([\n",
    "    # This Input shape is now (24, 3) automatically\n",
    "    Input(shape=(TIME_STEPS, N_FEATURES)), \n",
    "    LSTM(units=50, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=1) \n",
    "])\n",
    "\n",
    "# --- 3. Compile and Train ---\n",
    "print(\"\\n--- Training LSTM Model on SELECTED Features ---\")\n",
    "model_lstm_simple.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "history = model_lstm_simple.fit(\n",
    "    X_seq_train, Y_seq_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_seq_test, Y_seq_test),\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"--- Model Training Complete ---\")\n",
    "\n",
    "# --- 4. Evaluate the LSTM Model ---\n",
    "predictions_scaled = model_lstm_simple.predict(X_seq_test)\n",
    "predictions_real = target_scaler.inverse_transform(predictions_scaled)\n",
    "Y_test_real = target_scaler.inverse_transform(Y_seq_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_real, predictions_real))\n",
    "print(f\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Test RMSE: {rmse:.4f} (degrees C)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8148f6f-a704-4ed7-a28d-0d0cb43ecad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
